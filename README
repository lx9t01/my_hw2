// README

PART 1

Question 1.1: Latency Hiding
The latency of an arithmetic instruction in GPU is approximately more than 10 ns (~10+ns),
and per clock cycle a GK110 can issue 2 instructions/warp * 4 warp/clock = 8 instructions. 
Each clock cycle takes 1ns, so with in each cycle there is at most 10 * 8 = 80 instructions
being executed (hidden). 


Question 1.2: Thread Divergence
(a)
Yes, there is thread divergence, Because foo() and bar() tend to have different latency 
and therefore are not synchronized. 

(b)
Yes, because for each therad, the threadIdx.x varies therefore each thread will be executing 
different numbers of multiplication. It's clearly a diverged thread, because the runtime varies, 
the threads are not synchronized. 
Or no (I am not sure about this answer) because if the block size is only one, then for each block
there will be only 1 thread being executed. The threadIdx.x could be same across different calcualtions, 
so it could be possible that the threads are synchronized. 

Question 1.3: Coalesced Memory Access
(a) Yes
Because the block is 32*32 float, and GPU cache line is 128 byte which corresponds to 32 floats. The 
address is continuous, and the access is aligned, each cache line can be write in within the same warp, 
so each row write of global memery (per warp) requires only 1 cache line access, and for the whole block it requires 32 times of access in total. 

(b) No
Because the block address is not continuous, each block element has blocksize.y distance with others, so
for each row the read process cannot be finished within a warp. The address is not aligned with the block
index. So this is not coalesced. 
This may require 32 times of cache line access (serialized), in total they only use 32 cache lines of data. 

(c) No
This write is not aligned, and it will require 32 + 1 = 33 cache lines to fill the data. 

Question 1.4: Bank Conflicts and Instruction Dependencies
(a) No, there is no bank conflict in this way. 
lhs and rhs in shmem are all of stride 1, so the access will not cause bank conflict. 

(b) 
1) l1 = lhs[i + 32 * k];
2) r1 = rhs[k + 128 * j];
3) o1 = output[i + 32 * j];
4) o1 += l1 * r1;
5) output[i + 32 * j] = o1;
6) l2 = lhs[i + 32 * (k + 1)];
7) r2 = rhs[(k + 1) + 128 * j];
8) o2 = output[i + 32 * j];
9) o2 += l2 * r2;
10) output[i + 32 * j] = o2;

(c) 
for the first line of code, the instruction dependencies pairs are: 
4) depends on (use <= to show) 1);
4) <= 2)
4) <= 3)
5) <= 4)
similarly, the second line of code will have dependencies: 
9) <= 6)
9) <= 7)
9) <= 8)
10) <= 9)
also, between the two lines of code we should realize that 
3 <= 10)
8) <= 5) 
that each value should be stored before it can be taken again. 

(d) minimum number of variables used, and minimized number of instructions
(ILP implemented in the question (e))
int i = threadIdx.x;
int j = threadIdx.y;
for (int k = 0; k < 128; k += 2) {
	int l1 = lhs[i + 32 * k];
	int l2 = lhs[i + 32 * (k + 1)];
	int o = output[i + 32 * j];
	o += l1 * r1;
	int r1 = rhs[k + 128 * j];
	int r2 = rhs[(k + 1) + 128 * j];
	o += l2 * r2;
	output[i + 32 * j] = o;
}
The dependencies being removed are the step 5) and 8), which stores and reads in the value of output again

(e)
We can further improve the runtime by applying ILP, arranging the memory read and calculation separately, overlapping the total memory read/write, to minimize the number of memory transactions to hide latency. 
int i = threadIdx.x;
int j = threadIdx.y;
for (int k = 0; k < 128; k += 2) {
	int l1 = lhs[i + 32 * k];
	int l2 = lhs[i + 32 * (k + 1)];
	int r1 = rhs[k + 128 * j];
	int r2 = rhs[(k + 1) + 128 * j];
	int o = output[i + 32 * j];
	o += l1 * r1;
	o += l2 * r2;
	output[i + 32 * j] = o;
}
Or we might want to use loop unfold to further inprove the GPU speed. 

PART 2
Index of the GPU with the lowest temperature: 2 (40 C)
Time limit for this program set to 10 seconds
Size 512 naive CPU: 0.003744 ms
Size 512 GPU memcpy: 0.035744 ms
Size 512 naive GPU: 0.101600 ms
Size 512 shmem GPU: 0.049920 ms
Size 512 optimal GPU: 0.048352 ms

Size 1024 naive CPU: 1.685216 ms
Size 1024 GPU memcpy: 0.085728 ms
Size 1024 naive GPU: 0.309472 ms
Size 1024 shmem GPU: 0.155712 ms
Size 1024 optimal GPU: 0.151456 ms

Size 2048 naive CPU: 34.277855 ms
Size 2048 GPU memcpy: 0.268544 ms
Size 2048 naive GPU: 1.142784 ms
Size 2048 shmem GPU: 0.552384 ms
Size 2048 optimal GPU: 0.545248 ms

Size 4096 naive CPU: 153.340607 ms
Size 4096 GPU memcpy: 1.007552 ms
Size 4096 naive GPU: 4.134528 ms
Size 4096 shmem GPU: 2.166912 ms
Size 4096 optimal GPU: 2.117216 ms

I applied loop unfold and instruction level parallelism to optimize the algorithm, yet the 
improvement is not very obvious. 


BONUS
1, there will be more times of memory access in the first method with two separate vec_add call; 
1.1, or there moght be more IO access for the first instruction, as there will be more read/write from
either shared memory, global memory or even registers. 
2, sometimes there are instruction sets that allows 3 element add for certain hardware or operation system, 
it's a hardware based bottom-level optimization that could probably speed up the add for three elements. 
2.1, Also, the second approach will TEND TO use more register access than memory access, potentially speed
up the 3-element add. 
